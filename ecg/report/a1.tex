\documentclass{article}

\usepackage{fullpage}
\usepackage[latin1]{inputenc}
\usepackage[danish]{babel}
\usepackage{listings}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{abstract}
\usepackage{url}
\usepackage{float}
\usepackage{enumitem}
\usepackage[all]{xy}
\usepackage{amstext}
\usepackage{fancybox}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage[bottom]{footmisc}

% styling
\newcommand{\code}[1]{\texttt{#1}}

% diagrams
\newcommand{\switch}[1]%
  {\ovalbox{\text{\begin{minipage}{1.2in}\centering #1\end{minipage}}}}
\newcommand{\minibox}[1]%
  {\ovalbox{\text{\begin{minipage}{0.85in}\centering #1\end{minipage}}}}

\pagestyle{fancy}
\fancyhf{}
\setlength{\parindent}{0pt}
\setlength{\headheight}{15pt}
\setlength{\headsep}{25pt}
\lfoot{Side \thepage{} af \pageref{LastPage}}
\rfoot{30/09-2013}
\lhead{Embedded Systems}
\chead{Assignment 1}
\rhead{}

\title{Assignment 1}
\date{30.09.2013}
\author{
  Simon Altschuler\\
  \code{s1236563}
  \and
  Markus Færevaag\\
  \code{s123692}
}

\begin{document}
\maketitle
\clearpage

\tableofcontents
\clearpage


\section{Introduktion}
Denne opgaver omhandler processering af signaler fra et Elektrokardiogram apparat (herefter ECG). Formålet er omdanne de rå signaler til filtreret og fortolket data, som kan bruges til at måle puls og spænding, og advare om forestående problemer hos patienten.

Data fra ECG hardwaren er simuleret ved at læse linier af tal fra en tekstfil, således at rigtig data i princippet kunne bruges uden at ændre andet end funktionen der henter et nyt sample.


\section{Problemstilling}
Udfordringen i denne opgave er at implementere signalfiltre og detektere egenskaber effektivt og struktureret, samt at præsentere dataen for brugeren på en hensigtsmæssig og brugbar facon.

Da datasættene har op til flere millioner samples, er det vigtigt at implementere datastrukturer og algoritmer på en måde som kan håndtere arbitræt store datasæt, mens ydeevnen forbliver acceptabel.

Det er ydermere afgørende, at algoritmen giver korrekte resultater, da diagnosticeringen af en patient i modsat fald kan være forkert og lede til forkerte eller manglende beslutninger.


\subsection{Funktioner}
Følgende er de overordnede funktioner som programmet skal udføre. Vi kigger her på hvad de hver især skal udføre og hvad der er vigtigt at fokusere på.

\subsubsection{Sensor}
Sensoren kobles til patienten og laver et digitalt signal udfra den elektriske aktivitet fra hjertet. Dette simulerer vi ved at læse linje for linje af en fil indeholdende forskellige test data. Dette er simuleringen af hardwaren, og derfor bør denne funktion også have en forsinkelses mekanisme for at emulere det rigtige tidsinterval mellem samples (4ms mellemrum). Funktionen skal hente data on-the-fly og altså ikke indlæse alt i memory, da det vil være uhensigtsmæssigt for store datasæt, og det ydermere er et krav i den stillede opgave.

\subsubsection{Filtre}
Der er en række af filtre, som hver skal udføre én bestemt filtrering, eller transformation, af dataen. De er linært afhængige af hinanden, hvilket vil sige at de skal udføres i en bestemt rækkefølge og den næste afhænger af den forrige. Filtrene skal bruge tidligere målte samples og tidligere filtreret data, hvilket vil sige at der skal gemmes data. Da det er uhensigtsmæssigt, både hukommelses- og ydelsesvis, skal der udvikles en datastruktur som holder forbruget til et minimum.

\subsubsection{Peak detektion}
Detektion af peaks er en kompliceret algoritme, som bruger det filtrede data til at måle amplitude og og frekvens af patientens puls. Funktionen skal videregive dens resultater til display og output funktionerne, så det er vigtigt at denne data er tilgængelig på en brugbar facon.

\subsubsection{Output}
Det skal være muligt at skrive den resulterende data til en ekstern data fil, til brug for analyse, f.eks. i form af plots og grafer.

\subsubsection{Display}
Måden dataen bliver præsenteret er en afgørende faktor for brugervenligheden af programmet. Derfor har vi i tillæg til output til en fil, valgt at implementere en display feature som efterligner en rigtig ECG maskines output. Dataen behandles i realtid, med mulighed for at skalere tiden op og ned, og der vises essentielle data såsom puls (BPM), R-peak værdier, antal missede peaks, osv. Ydermere vil vi vise en graf af den rå data fra hardwaren i form af en simpel graf, sådan at pulsslagene kan ses visuelt.


\section{Design}
\label{sec:design}
Programmet tager en række options som styrer output, display og data. De er som følger:

\begin{description}[labelindent=1cm, labelwidth=1.5cm]
  \item[\code{-f $file$}] Angiv hvilken fil der skal bruges som testdata input
  \item[\code{-o $file$}] Angiv at data ønskes gemt som csv, argumentet er filen
  \item[\code{-l $uint$}] Angiver antal samples der skal køres, sættes normalt til antal linier i testdata filen
  \item[\code{-d}] Angiver at der ønskes visuel repræsentation af programmets kørsel
  \item[\code{-t $float$}] Tidsskalering, 2 = dobbelt hastighed, 0.5 = halv hastighed osv.
\end{description}

De forskellige dele af programmet skal hver især initialiseres og destrueres ved programstart og -slut. Derfor har de fleste features en \code{init} og \code{destroy} funktion, i hvilken de udføre de relevante operationer, hvad enten det være at initialisere et array eller åbne en fil. Dette hjælper på isolering af ansvar, og er med til at holde \code{main} funktionen clean.

\subsection{Arkitektur}

\begin{figure}[H]
\label{fig:flow}
\xymatrix{
  \ar@{->}[r]_{raw} \switch{sensor} & \ar@{->}[r]_{mwi} \switch{filter} & \ar@{.>}[r]_{data} \ar@{.>}[rd]_{data} \switch{peak detektion} & \switch{output} \\
  & & & \switch{display}
}
\caption{Overordnet program flow (stiplede linjer markere valgfri eksekvering)}
\end{figure}

Programmet er hovedsageligt opdelt i filerne \code{sensor.c}, \code{filter.c}, \code{peak\_detect.c}, \code{output.c} og \code{display.c}, som svarer direkte overens med de ovenfor beskrevne funktioner. Figur \ref{fig:flow} viser hvordan dataen går gennem rækken af komponenter, fra det rå data til det processerede resulterende data.

Dette flow giver en overskuelig inddeling af programmet da hver fil, i henhold med navnet, er ansvarlig for en isoleret og veldefineret opgave. Det er også med til at simulere en realistisk hardware struktur hvor komponenterne ville være implementeret hver for sig og videregive information på lignende vis.

Følgende er kort om hvordan arkitekturen indenfor hvert komponent er designet.

\subsection{Sensor}
Innlesningen av bildet skjer paa den maate at den best skal simulere signalet fra en ECG maskin. Derfor leses test dataen inn og behandles linje for linje, i motsetning til aa lese inn hele filen. Dette ville konsumere meget hukommelse, i tillegg ikke viser en god simulering av hvordan det faktisk fungerer.

\subsection{Filtre}
Filtrene er implementeret hver for sig, således at hvert filter er en separat funktion. For nemt at kunne anvende disse funktioner har vi samlet dem i en funktion kaldet \code{apply\_all\_filters}. Denne tager en rå værdi fra sensoren, filtrerer denne med \code{low\_pass}, \code{high\_pass}, \code{derivate}, \code{squaring} og \code{moving\_window\_integration}, for så at returnere \code{mwi} køen. På denne måde er de specifikke filtreringsfunktioner abstraheret væk.

\subsection{Peak detektion}
Vores peak detektion er en forholdsvis kompleks algoritme der bruker de senest filtrerede værdier. Der eksponeres én funktion, \code{update\_peak} som bruger MWI dataen og den nuværende tid. Algoritmen returnerer en \code{peak\_update} struct, der beskriver algoritmens resultater, og som danner grundlag for det den endelige repræsentation til brugeren.

\subsection{Output}
Skrivning til en fil gøres med \code{update\_output} funktionen, som tager en \code{peak\_update} struct. Der skrives til den angivne fil én linie per data cyklus. På denne måde kan vi meget let inkludere eller eksludere data til outputtet. Filen skrives i formattet CSV da det er meget simpelt og let at håndtere.

\subsection{Display}
Ligesom output håndteres visuel præsentation af data ved kald til \code{update\_display}, som også tager en \code{peak\_update} struct. Her opdateres skærmen med den ny data og grafen tegnes på ny. Når visuel præsentation er slået til (med \code{-d}) pauser programmet og afventer et keyboard input, før det afslutter, så man kan nå at se de sidst målte data.


\section{Implementering}
\subsection{Hjælpefunktioner}
Udover de benævnte komponenter, som hver har sin egen fil, har vi skrevet nogle hjælpefunktioner til array (\code{array\_utils}) og matematiske operationer (\code{math\_utils}). De matematiske operationer afgrænser sig til \code{min} og \code{max} funktioner. Array funktionerne abstraherer opgaven at prepende et element til et array, samt eksponerer en \code{array\_average}, der som navnet hentyder udregner et gennemsnit af værdierne i et array.

\subsection{Datastrukture}
De fleste af programmets interne dele benytter fixed-size FIFO\footnote{First In - First Out} køer. Vi prepender, altså sætter ind i arrayets første position, da dette gør det meget nemmere at bruge tidligere målt data. Hvis man eksempelvis skal bruge $X_{n-7}$ fra MWI skrives \code{mwi[7]}, hvilket er pænere, nemmere og mere overskueligt end at skulle holde styr på arrayets længde.

Køerne er implementeret med arrays, og når der prependes shiftes alle elementer i arrayet én plads til højre, og efterfølgende sættes element på position 0 til den nye værdi. På den måde bliver sidste element overskrevet af det næstsidste og vi undgår hukommelses leaks.

\subsection{Sensor}
Sensoren implementeres i tre dele. Første del initialiserer sensoren, \code{init\_sensor}. Der gives et filnavn som argument, og denne fil åbnes, med read permissions.

Derefter kan man kalde funktionen \code{get\_next\_data}, som læser én linie i filen som en integer og returnere denne. Sensoren gemmer intet data, det overlades til de andre komponenter som skal bruge det.

Ved programmets exit kaldes \code{destroy\_sensor}, som lukker input filen.

\subsection{Filtre}
Hver af de fem filtre er implementeret i deres egen funktion, som tager data fra den forrige filterfunktion og returnerer ny filtreret data. Selve filter algoritmene er implementert i følge formlene givet opgaven.

\begin{figure}[H]
\centering
\label{fig:filters}
\xymatrix{
  \ar@{->}[r] \minibox{low\_pass} & \ar@{->}[r] \minibox{high\_pass} & \ar@{->}[r] \minibox{derivative} & \ar@{->}[r] \minibox{square} & \minibox{mwi} &  \\
}
\caption{Respektive filterfunktioner}
\end{figure}
% TODO
Ved filtrering af dataen skal der bruges et array for hvert filter i hvilket resultaterne af det respektive filter bliver gemt. Ydermere skal man være omhyggelig med i hvilken rækkefølge de eksekveres, da de afhænger af hinanden. Dette bliver hurtigt kompliceret, og derfor har vi ligesom i de andre komponenter implementeret en \code{init\_filters} metode som initialisere de forskellige arrays. Vi har \code{typedef}'et et array med buffer størrelsen (til navnet \code{list}) for at gøre det mere overskueligt hvad de forskellige arrays er. 

Længden på disse lister er 33, da visse filtre skal bruge data fra 32 samples tilbage, plus de skal holde det nuværende sample.

Selve filtreringen foregår ved at kalde \code{apply\_all\_filters} med den rå data som argument, og denne funktion sørger for at kalde filtrene i korrekt rækkefølge og returnerer \code{mwi} listen.

De specifikke filterfunktioner er deklareret \code{static} da de ikke har nogen værdi udenfor \code{filters.c} filen.

\subsection{Peak detektion}
Peak detektion er implemeneret efter de givne instruktioner. Vi har brugt følgende start værdier for variabler nødvendigvis må initialiseres før algoritmen kan fungere:

\begin{description}[labelindent=1cm, labelwidth=3.5cm]
	\item[threshold1 = 2500]
      Den omtrentlige grænse for hvad der kan klasificeres som en R-peak
	\item[rr\_high = max]
      Max (sat til 99999), da første peak skal falde inden for high og low
	\item[spkf = 5000]
      Den omtrentlige R-peak værdi
	\item[npkf = 1000]
      Den omtrentlige gennemsnitlige peak værdi
\end{description}

For at fundne peaks og anden relevant data nemt kan videregives til næste del af programmet, har vi lavet en struct \code{peak\_update}, som indeholder det relevante data, såsom den seneste R-peak værdi, puls (\code{average1}), tid, seneste MWI værdi, etc. Denne struct videregives til både output, og display delene af programmet, som så kan bruge det data de har brug for.

\subsection{Display}
Det visuelle interface er udviklet ved brug af biblioteket \code{ncurses}\footnote{\url{http://www.gnu.org/software/ncurses}}. Det tager en \code{peak\_update} og viser essentielt set blot dens indhold. For at tegne puls grafen har \code{display} funktionen sin egen kø, for at den kan gemme de sidste 100 data punkter. Disse tegnes med en simpel algoritme der udregner række og kolonne position for et data punkt. Den er meget simpel og efterlader mulighed for megen forbedring, men den er stadig et fint proof of concept.

\subsection{Output}
Programmet kan skrive data til en given fil i CSV formattet. Dette kan så kan plottes til en graf med for eksempel programmeringssproget \code{R} (hvilket vi har gjort). Ligesom \code{sensor} funktionen, åbner \code{output} filen, der skal skrives til i \code{init\_output} funktionen. I \code{destroy\_output} lukkes filen igen.


\section{Resultater}
Nedenfor i figur \ref{fig:graph_good} vises den rå data og den relaterede filtrede (mwi) data. Det ses tydeligt hvordan algoritmen gør det utroligt meget nemmere at detektere amplitude og frekvens, da kurverne er blødere og næsten intet ``flimmer'' har.
\begin{figure}[H]
  \label{fig:graph_good}
  \centering
  \subfigure{\includegraphics[width=70mm]{graphs/graph_raw_good.pdf}}
  \subfigure{\includegraphics[width=70mm]{graphs/graph_mwi_good.pdf}}
  \caption{Normal puls, raw data og det filtrerede MWI}
\end{figure}

I figur \ref{fig:graph_bad} ses hvad der sker når patientens tilstand bliver kritisk. Pulsen stiger og slagkraften falder drastisk. Dette detekteres omgående i \code{peak\_detect} og der kan vises advarsler.

\begin{figure}[H]
  \centering
  \subfigure{\label{fig:raw_bad}\includegraphics[width=70mm]{graphs/graph_raw_bad.pdf}}
  \subfigure{\label{fig:mwi_bad}\includegraphics[width=70mm]{graphs/graph_mwi_bad.pdf}}
  \caption{Begyndende kritisk puls, raw data og det filtrerede MWI}
\end{figure}

Vi har implementeret algoritmen korrekt, i den forstand at den finder alle R-peaks korrekt. Den egentlige værdi af de funde peaks ligger en smule, dog konsistent, under toppunkterne på \code{mwi} dataen. Dette er vist i figur \ref{fig:peaks}.

\begin{figure}[H]
  \centering
  \includegraphics[width=10cm]{graphs/r_peaks.pdf}
  \label{fig:peaks}
  \caption{Fundne R-Peaks vist som cirkler på MWI data}
\end{figure}

Det visuelle output som vises når \code{-d} bruges, er vist i figur \ref{fig:screenshot}. Det ses hvordan rød farve er brugt til at markere alarmerende omstændigheder. 

\begin{figure}[H]
  \centering
  \includegraphics[width=15cm]{graphs/gui.png}
  \label{fig:screenshot}
  \caption{Visuelt output fra programmet, hvor det ses ud for ``Misses'' hvordan advarsler markeres}
\end{figure}

\section{Profiling}
\subsection{Flaskehalse}
Vi har profilet programmet med \code{gprof} og har observeret at det er array operationerne som udgør den klart dominerende del af køretiden. I et uoptimeret build udgør funktionen \code{prepend\_array\_int} næsten $60.5\%$ af CPU tiden, hvor den i et optimeret build udgør omkring $30.5\%$. Med denne information kunne man skære utrolig meget af køretiden ved at omskrive array operationerne til en hurtigere metode.

Vi fandt også at \code{apply\_mwi} filteret tager $33.5\%$ af køretiden i det uoptimerede build, og \code{apply\_all\_filters} hele $66\%$ i det optimerede. Det betyder at compileren har inlinet funktionen \code{apply\_mwi} (og formodentlig også alle de andre filter funktioner) i dens optimeringsfase således at filter instruktionerne bliver kørt direkte i \code{apply\_all\_filters}. Det er smart da der elimineres et funktions kald, men det kan i visse situationer øge kodestørrelsen. Det bør nævnes at vi kunne have gjort dette eksplicit ved at benytte keywordet \code{inline} på filter funktionerne, da det i så fald også ville være inlined i det uoptimerede build.

Nedenfor ses det dominerende \code{gprof} output af det uoptimerede build (kørt med datasættet med $10800K$ samples)
\begin{lstlisting}
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ns/call  ns/call  name    
 60.55      5.37     5.37 64800000    82.89    82.89  prepend_array_int
 33.52      8.34     2.97 10800000   275.31   275.31  apply_mwi
  1.58      8.48     0.14 10800000    12.98    13.90  update_peak
\end{lstlisting}

Nedenfor ses det dominerende \code{gprof} output af det \code{O3} optimerede build (også kørt med datasættet med $10800K$ samples)
\begin{lstlisting}
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ns/call  ns/call  name    
 66.03      2.38     2.38                             apply_all_filters
 30.66      3.49     1.11 64800000    17.08    17.08  prepend_array_int
  1.66      3.55     0.06                             update_peak
\end{lstlisting}


\subsection{Kodestørrelse}
Kodestørrelsen varierer afhængig af hvad man undersøger. Først og fremmest ignorerer vi ting som antal linier og karakterer i kildekoden. Det giver ikke mening at se på disse ud fra et hardware mæssigt perspektiv, da stil og præferencer spiller en stor rolle, samt at kildekoden i sig selv er mere eller mindre irrelevant for det endelige resultat efter kompilering.

\begin{table}[h]
  \label{tbl:codesize}
  \centering
  \begin{tabular}{l|l|l|l|l|l}
                 & -O0   & -O1             & -O2             & -O3             & -Os             \\ \hline
    bin          & 20380 & 19799 (97.15\%) & 19799 (97.15\%) & 19847 (97.38\%) & 19794 (97.12\%) \\ \hline
    .text        & 6072  & 4552  (74.97\%) & 4776  (78.66\%) & 4808  (79.18\%) & 3976  (65.48\%) \\ \hline
    update\_peak & 1669  & 1296  (77.65\%) & 1258  (75.37\%) & 1258  (75.37\%) & 1130  (67.71\%) \\
  \end{tabular}
  \caption{Kodestørrelse (bytes) af forskellige aspekter og optimeringer}
\end{table}

Vi har målt kodestørrelse på 5 forskellige builds, med compiler flags O0-O3 og Os. O0-O3 optimerer for køretid og vi forventer dermed ikke at kodestørrelsen nødvendigvis er lavere. Derimod optimerer Os netop for størrelse så her burde vi kunne se tydelig forskel. 

Tabel \ref{tbl:codesize} viser de målinger vi er kommet frem til, og hvor stort det er i forhold til O0 buildet. ``bin'' er simpelthen størrelsen på den binary der bliver kompileret. ``.text'' er målt vha. unix programmet \code{size}\footnote{\url{http://unixhelp.ed.ac.uk/CGI/man-cgi?size}} og måler størrelsen af instruktionssektoren af en binary, som er der hvor de egentlige instruktioner som CPU'en vil udføre ligger. ``update\_peak'' er størrelsen af \code{update\_peak} funktionen og er målt vha. unix programmet \code{nm}\footnote{\url{http://unixhelp.ed.ac.uk/CGI/man-cgi?nm}}, som viser information om forskellige symboler i en object fil (binary). Vi målte størrelsen af \code{update\_peak} funktionen fordi det er den største og derfor kan give den bedste sammenligning.

Det er interessant at den samlede binarys størrelse kun variere med \~500 bytes, selv i Os buildet. Det skyldes formodentlig at der ikke er specielt meget kode samlet set, hvilket bekræftes af at instruktionssættet udgør \~20\% af de totale bytes. I O3 buildet er koden generelt større end i O1 og O2, hvilket ikke er bemærkelsesværdigt, men det er interessant at \code{update\_peak} funktionen fylder mindre, og et tegn på at compileren er i stand til optimere kompakt og indviklet kode til noget langt mere optimalt.

\subsection{Køretid}
Algoritmen er af natur linær, den foretager de nøjagtig samme instruktioner (bortset fra init og destroy funktionerne), blot flere gange ved større input. Derfor forventer vi en køretid på $O(n)$. Vi har dog alligevel foretaget en måling og resultatet ses i figur \ref{fig:runtime}. Det ses at køretiden meget præcist er linær.

\begin{figure}[H]
  \centering
  \includegraphics[width=10cm]{graphs/running_time.pdf}
  \label{fig:runtime}
  \caption{Fundne R-Peaks vist som cirkler på MWI data}
\end{figure}



\subsection{Metode til målinger}
Vi har skrevet to \code{zsh}\footnote{\url{http://www.zsh.org}} scripts til at hjælpe med målingen af performance. Disse er inkluderet her, men af relevanshensyn ikke forklaret nærmere

Til måling af køretider
\begin{lstlisting}
for ((i = 0; i < 10000000; i = i + 1000000)); do 
    time bin/ecgo3 -f test_data/ECG10800K.txt -l $i; 
done;
\end{lstlisting}

Til måling af kodestørrelser
\begin{lstlisting}
for x (0 1 2 3 s); do 
    size -A bin/ecgo$x | grep .text; 
done;
\end{lstlisting}

\subsection{Energiforbrug}
Vi vil prøve at måle hvor meget energi der forbruges under kørsel af algoritmen. Vi har brugt en Intel i7 3537U CPU, og den har et energiforbrug på $17W$\footnote{\url{http://www.intel.com/content/www/us/en/processors/core/core-i7-processor/Corei7Specifications.html}}. Den samlede køretid af $10800K$ samples var $4.734 sek$. Dermed får vi følgende forbrug:

\begin{align}
Energiforbrug_{cpu} &= 17W \\
Samples &= 10800000 \\
Tid_{total} &= 4.734s \\
Tid_{100k} &= \frac{Tid_{total}}{Samples} \cdot 100000 = 0.04383s \\
Energi_{100K} &= Energiforbrug_{cpu} \cdot Tid_{100k} = 0.7452~watt~sekunder~(Joule) \\
\end{align}

Der bliver altså brugt $0.7452~Ws$ per $100K$ processerede samples. Hvis vi omregner til pris i Danmark og sætter prisen til $2.1\frac{kr}{kWh}$\footnote{\url{http://www.elpristavlen.dk/Elpristavlen/Soegeresultat.aspx?kwh=2000&postnr=2500&netcompany=DONGnet&customer-group=private&ratetype=FlatRate}} fås:

\begin{align}
Pris_{kWh} &= 2.1\frac{kr}{kWh} \\
Energi_{100K} &= 0.7452Ws = 2.07 \cdot 10^{-7} kWh \\
Pris_{100K} &= Energi_{100K} * Pris_{kWh} = 4 \cdot 10^{-5} øre
\end{align}

Det koster altså $0.00004 øre$ at processere $100.000$ samples.

\section{Diskussion}


\section{Konklusion}

\section{Kørsel af programmet}
En optimeret binary kan bygges ved at køre \code{make ecgo3} og derefter eksekvere programmet med de ønskede argumenter. F.eks. for at bruge ``ECG.txt'' og se den visuelle repræsentation af programmet i normal tid, kan det køres således: \code{ecgo3 -f ECG.txt -d -t 1}. Se \ref{sec:design} for detaljer vedr. argumenter.

\end{document}
